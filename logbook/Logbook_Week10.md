## Meeting (Date: 30/07/2025)

**Present:** Cheng Marceline (CM, student), Pain Christopher (PC, supervisor), James Coupe (J, supervisor), Joshi Aniket C (supervisor)

**Key points discussed:**

- Reviewed progress on the 4-stage bird animation pipeline from single image input to video generation with skeleton-based motion control.
- CM successfully completed stages 1-3: keypoint detection using HR-Net on CUB dataset, skeleton motion sequence generation using mathematical models, and video generation using stable diffusion with OpenPose ControlNet.
- Identified challenges with keypoint detection for overlapping features (wings, eyes, legs) due to side-angle bird images in training dataset.
- CM demonstrated video generation results using multiple approaches including anime diffusion, Canny edge detection, and OpenPose ControlNet, with the latter showing most promise for stable frame generation.
- Discussed integration plans with Zeke's surreal bird images as input for the animation pipeline.

**Feedback received:**

- PC requested to see actual video output rather than individual frames to better assess temporal consistency and motion quality.
- J suggested exploring DeepLabCut for animal tracking and keypoint detection, which CM confirmed was already being considered.
- PC proposed exploring bird-environment interactions (landing on trees, obstacle navigation) as future enhancement to the control algorithm.
- J conceptualized the project as creating an "aviary" of diverse synthetic birds with potential for interactive gallery installations where birds respond to viewer proximity.
- Supervisors emphasized the importance of achieving universal workflow capable of animating various bird morphologies generated by collaborator Zeke.
- AC expressed satisfaction with current progress and inquired about timeline for integrating surreal bird inputs.

**Work plan before next meeting:**

- Address temporal consistency issues in stage 4 and improve feature preservation to maintain bird appearance across frames.
- Generate and share complete video sequences (not just selected frames) to demonstrate motion quality and identify remaining issues.
- Experiment with Animal ControlNet as alternative to OpenPose for better non-human skeleton handling.
- Test pipeline with Zeke's surreal bird images to evaluate generalization capability.
- Investigate methods for bird-environment interaction, starting with simple scenarios like landing on surfaces.
- Create additional training data with birds showing both wings and eyes visible to improve keypoint detection accuracy.