#!/usr/bin/env python
# 02-2_vis_dataset.py
# å¯è§†åŒ–æ”¹è¿›åçš„æ•°æ®é›†ï¼Œæ˜¾ç¤ºæ›´å¤šç»Ÿè®¡ä¿¡æ¯

import json, random, cv2, yaml
import matplotlib.pyplot as plt
from pathlib import Path
import numpy as np

ANN = Path("data/merged17/train.json")  # ä½¿ç”¨æ”¹è¿›åçš„æ•°æ®
OUT = Path("vis_dataset"); OUT.mkdir(exist_ok=True)

sche = yaml.safe_load(Path("skeleton.yaml").read_text())
edges = sche["skeleton"]

def draw(img, kp):
    """ç»˜åˆ¶å…³é”®ç‚¹å’Œéª¨æ¶"""
    # ç»˜åˆ¶éª¨æ¶è¿çº¿
    for (i, j) in edges:
        if kp[i, 2] > 0 and kp[j, 2] > 0:
            cv2.line(img, tuple(kp[i, :2].astype(int)), tuple(kp[j, :2].astype(int)), (0, 255, 0), 2)
    
    # ç»˜åˆ¶å…³é”®ç‚¹
    for idx, p in enumerate(kp):
        if p[2] > 0:
            color = (0, 0, 255)  # çº¢è‰²ä¸ºå¯è§ç‚¹
            cv2.circle(img, tuple(p[:2].astype(int)), 4, color, -1)
            # å¯é€‰ï¼šæ˜¾ç¤ºå…³é”®ç‚¹ç¼–å·
            cv2.putText(img, str(idx), tuple(p[:2].astype(int) + 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
    
    return img

def main():
    print("ğŸ” å¯è§†åŒ–æ”¹è¿›åçš„é¸Ÿç±»æ•°æ®é›†")
    print("=" * 50)
    
    if not ANN.exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {ANN}")
        print("è¯·å…ˆè¿è¡Œ 02-1_prepare_dataset.py")
        return
    
    js = json.loads(ANN.read_text())
    
    print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"   å›¾åƒæ•°é‡: {len(js['images'])}")
    print(f"   æ ‡æ³¨æ•°é‡: {len(js['annotations'])}")
    print(f"   ç±»åˆ«: {js['categories']}")
    
    if not js['annotations']:
        print("âŒ æ²¡æœ‰æ ‡æ³¨æ•°æ®")
        return
    
    # åˆ†æå…³é”®ç‚¹è´¨é‡
    keypoint_counts = [ann['num_keypoints'] for ann in js['annotations']]
    bbox_areas = [ann.get('area', 0) for ann in js['annotations']]
    
    print(f"\nğŸ¯ å…³é”®ç‚¹è´¨é‡åˆ†æ:")
    print(f"   å¯è§å…³é”®ç‚¹æ•°é‡:")
    print(f"     æœ€å°‘: {min(keypoint_counts)}")
    print(f"     æœ€å¤š: {max(keypoint_counts)}")
    print(f"     å¹³å‡: {np.mean(keypoint_counts):.1f}")
    print(f"     ä¸­ä½æ•°: {np.median(keypoint_counts):.1f}")
    
    print(f"\nğŸ“¦ Bboxè´¨é‡åˆ†æ:")
    valid_bboxes = [area for area in bbox_areas if area > 0]
    print(f"   æœ‰æ•ˆbboxæ•°é‡: {len(valid_bboxes)}/{len(bbox_areas)}")
    if valid_bboxes:
        print(f"   å¹³å‡é¢ç§¯: {np.mean(valid_bboxes):.0f} åƒç´ Â²")
    
    # æŒ‰å…³é”®ç‚¹æ•°é‡åˆ†ç»„ç»Ÿè®¡
    print(f"\nğŸ“ˆ å…³é”®ç‚¹åˆ†å¸ƒ:")
    for kpt_count in range(min(keypoint_counts), max(keypoint_counts) + 1):
        count = sum(1 for x in keypoint_counts if x == kpt_count)
        if count > 0:
            print(f"   {kpt_count:2d} ä¸ªç‚¹: {count:4d} ä¸ªæ ·æœ¬")
    
    # å¯è§†åŒ–æ ·æœ¬
    print(f"\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–æ ·æœ¬...")
    
    # é€‰æ‹©ä¸åŒè´¨é‡çš„æ ·æœ¬è¿›è¡Œå¯è§†åŒ–
    samples_to_vis = []
    
    # é«˜è´¨é‡æ ·æœ¬ï¼ˆå…³é”®ç‚¹å¤šï¼‰
    high_quality = [ann for ann in js['annotations'] if ann['num_keypoints'] >= 12]
    if high_quality:
        samples_to_vis.extend(random.sample(high_quality, min(3, len(high_quality))))
    
    # ä¸­ç­‰è´¨é‡æ ·æœ¬
    medium_quality = [ann for ann in js['annotations'] if 8 <= ann['num_keypoints'] < 12]
    if medium_quality:
        samples_to_vis.extend(random.sample(medium_quality, min(3, len(medium_quality))))
    
    # ä½è´¨é‡æ ·æœ¬
    low_quality = [ann for ann in js['annotations'] if ann['num_keypoints'] < 8]
    if low_quality:
        samples_to_vis.extend(random.sample(low_quality, min(2, len(low_quality))))
    
    # å¦‚æœæ ·æœ¬ä¸å¤Ÿï¼Œéšæœºè¡¥å……
    while len(samples_to_vis) < 10 and len(js['annotations']) > len(samples_to_vis):
        remaining = [ann for ann in js['annotations'] if ann not in samples_to_vis]
        samples_to_vis.extend(random.sample(remaining, min(10 - len(samples_to_vis), len(remaining))))
    
    saved_count = 0
    for ann in samples_to_vis:
        # æ‰¾åˆ°å¯¹åº”çš„å›¾åƒä¿¡æ¯
        img_info = next((i for i in js["images"] if i["id"] == ann["image_id"]), None)
        if not img_info:
            continue
            
        path = Path("data") / img_info["file_name"]
        kp = np.array(ann["keypoints"]).reshape(-1, 3)

        # è¯»å–å¹¶å¯è§†åŒ–å›¾åƒ
        im = cv2.imread(str(path))
        if im is None:
            print(f"âš ï¸  æ— æ³•è¯»å–å›¾åƒ: {path}")
            continue

        # ç»˜åˆ¶å…³é”®ç‚¹å’Œéª¨æ¶
        vis = draw(im.copy(), kp)
        
        # æ·»åŠ ä¿¡æ¯æ–‡å­—
        info_text = f"ID:{img_info['id']} Points:{ann['num_keypoints']} BBox:{ann.get('area', 0):.0f}"
        cv2.putText(vis, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        output_file = OUT / f"{img_info['id']:06d}_kpts{ann['num_keypoints']:02d}.jpg"
        cv2.imwrite(str(output_file), vis)
        saved_count += 1
        
        print(f"   ä¿å­˜: {output_file.name} (å…³é”®ç‚¹: {ann['num_keypoints']})")

    print(f"\nâœ… å¯è§†åŒ–å®Œæˆ!")
    print(f"   ä¿å­˜äº† {saved_count} ä¸ªæ ·æœ¬åˆ°: {OUT}")
    print(f"   å¯ä»¥æŸ¥çœ‹ä¸åŒè´¨é‡çš„å…³é”®ç‚¹æ ‡æ³¨æ•ˆæœ")
    
    # å¦‚æœæ•°æ®è´¨é‡æ”¹å–„æ˜æ˜¾ï¼Œç»™å‡ºæç¤º
    if np.mean(keypoint_counts) >= 10:
        print(f"\nğŸ‰ æ•°æ®è´¨é‡è‰¯å¥½! å¹³å‡ {np.mean(keypoint_counts):.1f} ä¸ªå¯è§å…³é”®ç‚¹")
        print(f"   ç°åœ¨å¯ä»¥ç»§ç»­è¿è¡Œ 03_train_hrnet.py è¿›è¡Œè®­ç»ƒ")
    elif np.mean(keypoint_counts) >= 8:
        print(f"\nâœ… æ•°æ®è´¨é‡å¯æ¥å—, å¹³å‡ {np.mean(keypoint_counts):.1f} ä¸ªå¯è§å…³é”®ç‚¹")
        print(f"   å¯ä»¥å°è¯•è®­ç»ƒï¼Œä½†å¯èƒ½éœ€è¦è°ƒæ•´è®­ç»ƒå‚æ•°")
    else:
        print(f"\nâš ï¸  æ•°æ®è´¨é‡ä»éœ€æ”¹è¿›, å¹³å‡åªæœ‰ {np.mean(keypoint_counts):.1f} ä¸ªå¯è§å…³é”®ç‚¹")
        print(f"   å»ºè®®æ£€æŸ¥æ•°æ®é¢„å¤„ç†è¿‡ç¨‹")

if __name__ == "__main__":
    main()